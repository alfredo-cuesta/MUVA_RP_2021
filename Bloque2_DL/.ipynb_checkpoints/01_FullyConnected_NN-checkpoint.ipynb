{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KI5HO6c0MQy"
   },
   "source": [
    "# Redes neuronales totalmente conexas \n",
    "\n",
    "En este cuaderno vamos a construir redes neurnales *clásicas\", es decir tal y como se concebían antes de la llegada del *Deep Learning\".\n",
    "\n",
    "Este tipo de redes recibe diversos nombres: <br>\n",
    " · En inglés se denominan habitualmente **_MultiLayer Perceptron_ (MLP)** o **_Fully Connected_ (FC)**<br>\n",
    " · En castellano se traducen como **Perceptrón multicapa** (en mi opinión debería ser más bien _multicapa de perceptrones_), <br>\n",
    "$\\quad$**Totalmente conectadas/conexas**, y también **Densas** por influencia Tensorflow.\n",
    "\n",
    "Este tipo de redes no está ni mucho menos obsoleta, y se pueden encontrar en soluciones de Deep Learning como parte final de la red, para realizar la tarea para la que ha sido diseñada.\n",
    "\n",
    "---\n",
    "\n",
    "    [ES] Código de Alfredo Cuesta Infante para 'Reconocimiento de Patrones'\n",
    "       @ Master Universitario en Visión Artificial, 2021, URJC (España)\n",
    "    [EN] Code by Alfredo Cuesta-Infante for 'Pattern Recognition'\n",
    "       @ Master of Computer Vision, 2021, URJC (Spain)\n",
    "\n",
    "    alfredo.cuesta@urjc.es    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminares\n",
    "Paquetes de propósito general (_numpy_, _matplotlib_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kd8kmCJ8FzY"
   },
   "outputs": [],
   "source": [
    "#-[0]. General purpose packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a36yDHQK0Tny"
   },
   "source": [
    "**Cargar el MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3090,
     "status": "ok",
     "timestamp": 1564080372050,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh4.googleusercontent.com/-z9Tr7G7VUMk/AAAAAAAAAAI/AAAAAAAAAAc/gH3qm0UbcIo/s64/photo.jpg",
      "userId": "17488335604138000921"
     },
     "user_tz": -120
    },
    "id": "1-qDDIYSvF0W",
    "outputId": "39b5aa89-d756-403c-e01f-c78416137732"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bc16b5712e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#-[1]. Load images. Keras has a few benchmark datasets readily available.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#-[1]. Load images. Keras has a few benchmark datasets readily available.\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#--- Get info of train and test data sets\n",
    "N_train,dim0,dim1 = x_train.shape\n",
    "N_test,dim0,dim1  = x_test.shape\n",
    "num_classes = 10\n",
    "num_pixels = dim0*dim1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjWNP6d00bdG"
   },
   "source": [
    "### Construcción de la red\n",
    "+ Una red densa tiene:\n",
    "    + Una capa de entrada\n",
    "    + Una o varias capas ocultas\n",
    "    + Una capa de salida\n",
    "\n",
    "Keras nos proporciona objetos para replicar esta estructura de capas\n",
    "+ **La capa de entrada** está compuesta por neuronas de entrada; tantas como el número de características (la dimensión) de los ejemplos. Cada neurona tiene una sola entrada, sus pesos están fijos a 1, su bias a 0 y su función de activación es lineal.\n",
    "+ **Cada capa oculta** consiste en un número de neuronas. Cada una de estas neuronas se conecta con todas las salidas de la capa anterior. Todas tienen (salvo que se diga lo contrario) un valor de bias diferente de 0, y la misma función de activación.\n",
    "+ **La capa de salida** es similar a una capa oculta, pero el número de neuronas y su función de activación depende de la tarea que vayamos a realizar.\n",
    "    + Si, por ej., vamos a hacer clasificación habrá una neurona por cada clase diferente y la función de activación será *Softmax*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3106,
     "status": "ok",
     "timestamp": 1564080372080,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh4.googleusercontent.com/-z9Tr7G7VUMk/AAAAAAAAAAI/AAAAAAAAAAc/gH3qm0UbcIo/s64/photo.jpg",
      "userId": "17488335604138000921"
     },
     "user_tz": -120
    },
    "id": "RtdiOOonwUcU",
    "outputId": "78cc47cd-f906-48aa-9ca3-2565add89761"
   },
   "outputs": [],
   "source": [
    "#-[2]. Modeling the neural network in three different ways\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "\n",
    "choice_code = 'all_in_one' # options are: 'all_in_one' , 'with_add' , 'stacking'\n",
    "num_hidden_neurons = 32\n",
    "\n",
    "if choice_code == 'all_in_one':\n",
    "  model = Sequential([\n",
    "      Dense(num_hidden_neurons, input_shape=(num_pixels,)),  #<-- input_shape requires ','\n",
    "      Activation('relu'),\n",
    "      Dense(num_classes),\n",
    "      Activation('softmax'),\n",
    "  ])\n",
    "\n",
    "elif choice_code == 'with_add':\n",
    "  model = Sequential()\n",
    "  model.add(Dense(num_hidden_neurons, input_dim=num_pixels))  #<-- input_dim does not !! \n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(num_classes))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "elif choice_code == 'stacking':  \n",
    "  x  = Input(shape=(num_pixels,))            #<-- shape requires ',' \n",
    "  h = Dense(num_hidden_neurons)(x)           #\n",
    "  h = Activation('relu')(h)                  #   BUT shape is a parameter of the Input layer\n",
    "  z = Dense(num_classes)(h)                  #   NOT of the Dense layer\n",
    "  y = Activation('softmax')(z)\n",
    "  model = Model(x,y)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1r2xGCF1tkW"
   },
   "source": [
    "### _Compilar_ el modelo\n",
    "\n",
    "+ Para compilar el modelo tenemos que seleccionar un optimizador y una función de pérdida.\n",
    "+ También se puede elegir un conjunto de métricas para evaluar el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3111,
     "status": "ok",
     "timestamp": 1564080372096,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh4.googleusercontent.com/-z9Tr7G7VUMk/AAAAAAAAAAI/AAAAAAAAAAc/gH3qm0UbcIo/s64/photo.jpg",
      "userId": "17488335604138000921"
     },
     "user_tz": -120
    },
    "id": "T5SWcJ36v3vA",
    "outputId": "63b4c91c-716d-43da-9975-9a1edc810f6c"
   },
   "outputs": [],
   "source": [
    "choice_problem = 'Nclasses' # options are: 'Nclasses', '2classes', 'regression'\n",
    "\n",
    "# For a multi-class classification problem\n",
    "if choice_problem == 'Nclasses':\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# For a binary classification problem\n",
    "elif choice_problem == '2classes':\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "elif choice_problem == 'regression':\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss='mse')\n",
    "\n",
    "else:\n",
    "  print('--- choose a valid option ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CfLnCDn7trc"
   },
   "source": [
    "## Aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWpsv3RW4c1u"
   },
   "source": [
    "**1. Preparamos el conjunto de datos para que pueda ser procesado por el modelo**  <br>\n",
    "       _En este caso tenemos que serializar las imágenes, de matrices $28\\times28$ a vectores de $784$_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYqb-Py14xRK"
   },
   "outputs": [],
   "source": [
    "x_flat = x_train.reshape( (N_train,num_pixels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_dmd2oZ2OhK"
   },
   "source": [
    "**2. Preparamos el vector de etiquetas para tenga una representación 1-hot**  <br>\n",
    "       _Si el problema no fuera multi-clase no sería necesario_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnBmx4De2FDa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_1hot = to_categorical(y_train, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjTuHuom21ng"
   },
   "source": [
    "**3. Ejecutar el método FIT**<br>estandar\n",
    "_Tensorflow sigue el estandar de Scikit-Learn. Pero a diferencia de otros métodos que hemos visto de ML, en DL hay que especificar algunas otra opciones como el número de épocas o el tamaño del lote.\n",
    "+ El **número de épocas** indica cuantas veces se utiliza el conjunto de entrenamiento para realizar el aprendizaje\n",
    "+ El **tamaño del lote** es el número de muestras que se utilizan para calcular el descenso del gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31742,
     "status": "ok",
     "timestamp": 1564080400818,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh4.googleusercontent.com/-z9Tr7G7VUMk/AAAAAAAAAAI/AAAAAAAAAAc/gH3qm0UbcIo/s64/photo.jpg",
      "userId": "17488335604138000921"
     },
     "user_tz": -120
    },
    "id": "Ta4SlQ_x244O",
    "outputId": "4d6df649-cdc1-448d-de82-30b2c3b16233"
   },
   "outputs": [],
   "source": [
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "N_epochs = 1\n",
    "batch_size = 32\n",
    "model.fit(x_flat, y_1hot, epochs=N_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCOOvn-U8yIy"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFV393Fb9SS2"
   },
   "source": [
    "**1. Debemos procesar los datos de test igual que procesamos los de entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHo0GJvV80Xw"
   },
   "outputs": [],
   "source": [
    "x = x_test.reshape( (N_test,dim0*dim1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. También pasamos el 'ground truth'** (las etiquetas del conjunto de test) **a una representación 1-hot**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHo0GJvV80Xw"
   },
   "outputs": [],
   "source": [
    "y = to_categorical( y_test, num_classes=num_classes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ejecutar el método PREDICT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H23IeqsK_A76"
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(x)\n",
    "#-> 'yhat' is the outcome of the NN = an array with 'num_classes' elements, with the probability of each class\n",
    "#      in other words, it is a PMF across all the possible classes\n",
    "\n",
    "class_hat = np.argmax(yhat, axis=-1)\n",
    "#-> 'class_hat' is the class with the highest probability\n",
    "\n",
    "class_prob = np.max(yhat, axis=-1)\n",
    "#-> 'class_prob' is the probability of 'class_hat'\n",
    "\n",
    "# NOTE: axis = -1 refers the last axis of the numpy array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ El método `evaluate` calcula el promedio de la pérdida y la(s) metrica(s) elegidas al compilar el modelo con tantos lotes como permita el tamaño del conjunto de datos y el tamaño del lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32400,
     "status": "ok",
     "timestamp": 1564080401548,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh4.googleusercontent.com/-z9Tr7G7VUMk/AAAAAAAAAAI/AAAAAAAAAAc/gH3qm0UbcIo/s64/photo.jpg",
      "userId": "17488335604138000921"
     },
     "user_tz": -120
    },
    "id": "EkRy5kBo8__w",
    "outputId": "ba3fc38f-ed86-4ed6-e52c-8e6b1444a08e"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x, y, batch_size=128)\n",
    "strlog = \"\\nEVALUATION: Loss = %0.2f %% , Accuracy = %0.2f %%\" %(score[0]*100, score[1]*100)\n",
    "print(strlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ También podemos probar a elegir una imágen y pasársela al modelo para que la clasifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32348,
     "status": "ok",
     "timestamp": 1564080401558,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh4.googleusercontent.com/-z9Tr7G7VUMk/AAAAAAAAAAI/AAAAAAAAAAc/gH3qm0UbcIo/s64/photo.jpg",
      "userId": "17488335604138000921"
     },
     "user_tz": -120
    },
    "id": "foSxBR40_pA-",
    "outputId": "9294443a-2107-4bcd-8c81-1d36cfd686fa"
   },
   "outputs": [],
   "source": [
    "k = 1234\n",
    "print( y[k,:],   '<-- y: number '    ,np.argmax(y[k,:]) ,'\\n')\n",
    "print( yhat[k,:],'<-- yhat:','number',class_hat[k] )\n",
    "plt.imshow(x_test[k,:,:])\n",
    "strtitle = 'It is a %d, with prob. = %0.2f' %(class_hat[k],class_prob[k])\n",
    "plt.title(strtitle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Crear la función `mi_modelo( x_shape, y_shape, layer_list )` que encapsule el modelo de tu red neuronal y reciba como parámetros las dimensiones del datos de entrada  y del vector de etiquetas.\n",
    "2. Modificar el modelo para que admita las imágenes como matrices $28\\times28$ en vez de como vectores de $784$ elementos. Para ello habrá que utilizar el método `Flatten` de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def mi_modelo(x_shape, y_shape, layer_list, activation = 'relu'):\n",
    "    x = Input(shape=x_shape)\n",
    "    h = Flatten()(x)\n",
    "    for num_h in layer_list:\n",
    "        h = Dense(num_h)(h)   \n",
    "        h = Activation(activation)(h)\n",
    "    z = Dense(y_shape)(h)\n",
    "    y = Activation('softmax')(z)\n",
    "    return Model(x,y)\n",
    "#================================================================\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "N_train,dim0,dim1 = x_train.shape\n",
    "N_test,dim0,dim1  = x_test.shape\n",
    "num_classes = 10\n",
    "y_1hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y = to_categorical(y_test, num_classes=num_classes)\n",
    "#-----------------------------\n",
    "N_epochs = 1\n",
    "batch_size = 32\n",
    "list_hidden_neurons = [32,20,10]\n",
    "#-----------------------------\n",
    "model = mi_modelo((dim0,dim1), num_classes, list_hidden_neurons)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_1hot, epochs=N_epochs, batch_size=batch_size)\n",
    "#-----------------------------\n",
    "yhat = model.predict(x_test)\n",
    "class_hat = np.argmax(yhat, axis=-1)\n",
    "class_prob = np.max(yhat, axis=-1)\n",
    "score = model.evaluate(x_test, y, batch_size=128)\n",
    "strlog = \"\\nEVALUATION: Loss = %0.2f %% , Accuracy = %0.2f %%\" %(score[0]*100, score[1]*100)\n",
    "print(strlog)\n",
    "#-----------------------------\n",
    "k = 1234\n",
    "print( y[k,:],   '<-- y: number '    ,np.argmax(y[k,:]) ,'\\n')\n",
    "print( yhat[k,:],'<-- yhat:','number',class_hat[k] )\n",
    "plt.imshow(x_test[k,:,:])\n",
    "strtitle = 'It is a %d, with prob. = %0.2f' %(class_hat[k],class_prob[k])\n",
    "plt.title(strtitle)\n",
    "plt.show()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "a36yDHQK0Tny",
    "kjWNP6d00bdG",
    "3CfLnCDn7trc",
    "JCOOvn-U8yIy"
   ],
   "name": "01_keras_FCNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
